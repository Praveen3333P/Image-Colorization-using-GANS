{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.utils import load_img, img_to_array\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess a single image\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = load_img(image_path, target_size=target_size, color_mode='rgb')\n",
    "    img_array = img_to_array(img)\n",
    "    return img_array\n",
    "\n",
    "# Function to convert RGB to Lab color space\n",
    "def rgb_to_lab(rgb_image):\n",
    "    return color.rgb2lab(rgb_image / 255.0)\n",
    "\n",
    "# Function to convert Lab to RGB color space\n",
    "def lab_to_rgb(lab_image):\n",
    "    return color.lab2rgb(lab_image) * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data generator\n",
    "def custom_image_generator(bw_dir, color_dir, batch_size):\n",
    "    try:\n",
    "        bw_files = [os.path.join(bw_dir, f) for f in os.listdir(bw_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        color_files = [os.path.join(color_dir, f) for f in os.listdir(color_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    except UnicodeEncodeError:\n",
    "        print(\"Error: File paths contain unsupported characters. Please ensure all file names use ASCII characters. Just make sure\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        batch_paths = list(zip(bw_files, color_files))\n",
    "        np.random.shuffle(batch_paths)\n",
    "        for i in range(0, len(batch_paths), batch_size):\n",
    "            batch_bw_paths, batch_color_paths = zip(*batch_paths[i:i+batch_size])\n",
    "            \n",
    "            batch_bw = np.array([load_and_preprocess_image(f) for f in batch_bw_paths])\n",
    "            batch_color = np.array([load_and_preprocess_image(f) for f in batch_color_paths])\n",
    "            \n",
    "            # Convert to Lab color space\n",
    "            batch_bw_lab = rgb_to_lab(batch_bw)[:, :, :, 0]\n",
    "            batch_color_lab = rgb_to_lab(batch_color)[:, :, :, 1:]\n",
    "            \n",
    "            # Normalize\n",
    "            batch_bw_lab = batch_bw_lab / 50.0 - 1.0\n",
    "            batch_color_lab = batch_color_lab / 128.0\n",
    "            \n",
    "            # Reshape grayscale images\n",
    "            batch_bw_lab = np.expand_dims(batch_bw_lab, axis=-1)\n",
    "            \n",
    "            yield batch_bw_lab, batch_color_lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the generator (U-Net architecture)\n",
    "def build_generator():\n",
    "    def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "        x = layers.Conv2D(n_filters, kernel_size, padding='same')(input_tensor)\n",
    "        if batchnorm:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(n_filters, kernel_size, padding='same')(x)\n",
    "        if batchnorm:\n",
    "            x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=(128, 128, 1))\n",
    "    conv1 = conv2d_block(inputs, 64)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv2d_block(pool1, 128)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = conv2d_block(pool2, 256)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = conv2d_block(pool3, 512)\n",
    "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv5 = conv2d_block(pool4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = layers.concatenate([up6, conv4])\n",
    "    conv6 = conv2d_block(up6, 512)\n",
    "    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = layers.concatenate([up7, conv3])\n",
    "    conv7 = conv2d_block(up7, 256)\n",
    "    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = layers.concatenate([up8, conv2])\n",
    "    conv8 = conv2d_block(up8, 128)\n",
    "    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = layers.concatenate([up9, conv1])\n",
    "    conv9 = conv2d_block(up9, 64)\n",
    "\n",
    "    outputs = layers.Conv2D(2, 1, activation='tanh')(conv9)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(128, 128, 3)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(512, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = layers.Input(shape=(128, 128, 1))\n",
    "    generated_image = generator(gan_input)\n",
    "    # Concatenate the input grayscale image with the generated ab channels\n",
    "    concatenated = layers.Concatenate()([gan_input, generated_image])\n",
    "    gan_output = discriminator(concatenated)\n",
    "    gan = models.Model(gan_input, gan_output)\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_gan(generator, discriminator, gan, epochs, steps_per_epoch, train_generator):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        d_losses = []\n",
    "        d_accuracies = []\n",
    "        g_losses = []\n",
    "        \n",
    "        for step in range(steps_per_epoch):\n",
    "            # Get a batch of images\n",
    "            bw_batch, color_batch = next(train_generator)\n",
    "\n",
    "            # Generate colorized images\n",
    "            generated_images = generator.predict(bw_batch)\n",
    "\n",
    "            # Concatenate real and fake inputs for discriminator\n",
    "            real_input = np.concatenate([bw_batch, color_batch], axis=-1)\n",
    "            fake_input = np.concatenate([bw_batch, generated_images], axis=-1)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = discriminator.train_on_batch(real_input, np.ones((bw_batch.shape[0], 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_input, np.zeros((bw_batch.shape[0], 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = gan.train_on_batch(bw_batch, np.ones((bw_batch.shape[0], 1)))\n",
    "\n",
    "            d_losses.append(d_loss[0])\n",
    "            d_accuracies.append(d_loss[1])\n",
    "            g_losses.append(g_loss)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f\"  Step {step+1}/{steps_per_epoch} [D loss: {d_loss[0]:.4f} | D accuracy: {100 * d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n",
    "\n",
    "        # Calculate average losses and accuracy for the epoch\n",
    "        avg_d_loss = np.mean(d_losses)\n",
    "        avg_d_accuracy = np.mean(d_accuracies)\n",
    "        avg_g_loss = np.mean(g_losses)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed in {epoch_time:.2f} seconds\")\n",
    "        print(f\"Average D loss: {avg_d_loss:.4f} | Average D accuracy: {100 * avg_d_accuracy:.2f}% | Average G loss: {avg_g_loss:.4f}\")\n",
    "        print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "        # Save generated images at the end of each epoch\n",
    "        save_generated_images(generator, bw_batch, color_batch, epoch + 1)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    print(f\"Total training time: {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_images(generator, bw_images, color_images, epoch, examples=5):\n",
    "    # Ensure we don't try to display more images than we have in the batch\n",
    "    examples = min(examples, bw_images.shape[0])\n",
    "    \n",
    "    generated_images = generator.predict(bw_images[:examples])\n",
    "    \n",
    "    fig, axs = plt.subplots(examples, 3, figsize=(15, 5*examples))\n",
    "    for i in range(examples):\n",
    "        if examples == 1:\n",
    "            current_ax = axs\n",
    "        else:\n",
    "            current_ax = axs[i]\n",
    "        \n",
    "        # Display black and white image\n",
    "        current_ax[0].imshow(bw_images[i, :, :, 0], cmap='gray')\n",
    "        current_ax[0].axis('off')\n",
    "        current_ax[0].set_title('Input (Grayscale)')\n",
    "        \n",
    "        # Display generated color image\n",
    "        gen_lab = np.concatenate([bw_images[i], generated_images[i]], axis=-1)\n",
    "        gen_rgb = lab_to_rgb(gen_lab)\n",
    "        current_ax[1].imshow(gen_rgb)\n",
    "        current_ax[1].axis('off')\n",
    "        current_ax[1].set_title('Generated')\n",
    "        \n",
    "        # Display original color image\n",
    "        orig_lab = np.concatenate([bw_images[i], color_images[i]], axis=-1)\n",
    "        orig_rgb = lab_to_rgb(orig_lab)\n",
    "        current_ax[2].imshow(orig_rgb)\n",
    "        current_ax[2].axis('off')\n",
    "        current_ax[2].set_title('Ground Truth')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"generated_images_epoch_{epoch}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "train_bw_path = r\"C:\\Users\\USER\\Downloads\\Capstone Redesigned\\data2\\train_black\"\n",
    "train_color_path = r\"C:\\Users\\USER\\Downloads\\Capstone Redesigned\\data2\\train_color\"\n",
    "test_bw_path = r\"C:\\Users\\USER\\Downloads\\Capstone Redesigned\\data2\\test_black\"\n",
    "test_color_path = r\"C:\\Users\\USER\\Downloads\\Capstone Redesigned\\data2\\test_color\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "steps_per_epoch = 25  # Adjust based on your dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = custom_image_generator(train_bw_path, train_color_path, batch_size)\n",
    "test_generator = custom_image_generator(test_bw_path, test_color_path, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5),\n",
    "            loss='binary_crossentropy')\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, epochs, steps_per_epoch, train_generator)\n",
    "\n",
    "# Save the generator model\n",
    "generator.save(\"colorization_generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save some test images\n",
    "test_bw_batch, test_color_batch = next(test_generator)\n",
    "save_generated_images(generator, test_bw_batch, test_color_batch, epoch=\"final\", examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
